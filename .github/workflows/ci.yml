name: CI/CD Pipeline

on:
  push:
    branches: ["**"]
    tags: ["v*"]
  pull_request:
    branches: [main]
  schedule:
    # Run quality gates daily at 2 AM UTC
    - cron: "0 2 * * *"
  workflow_dispatch:
    inputs:
      run_quality_gates:
        description: "Run comprehensive quality gates"
        required: false
        default: false
        type: boolean

# Group runs by workflow + branch/PR and cancel in-progress runs on new pushes
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  NODE_VERSION: "20"
  PNPM_VERSION: "10.18.3"
  NODE_OPTIONS: "--max-old-space-size=8192"
  # Disable Nx daemon in CI to prevent hanging issues
  NX_DAEMON: false
  # Skip Husky hooks in CI to prevent build loops
  HUSKY: 0
  CI: true
  # E2E test parallelism - number of shards for Playwright test distribution
  # Reduced from 20 to 12 due to systematic failures with 20 shards (resource contention)
  E2E_SHARDS: 12
  # Option B: Disable database cache if Option A (caching full .nx dir) doesn't work
  # Uncomment these three lines to fall back to legacy file-based caching:
  # NX_DISABLE_DB: true
  # NX_DB_CACHE: false
  # NX_REJECT_UNKNOWN_LOCAL_CACHE: false

jobs:
  # Syncpack - validates and auto-fixes dependency versions
  syncpack:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js with pnpm cache
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Setup Nx cache
        uses: actions/cache@v4
        with:
          # Cache full .nx dir (includes workspace-data DB) for cross-run cache sharing
          path: .nx
          key: ${{ runner.os }}-nx-v3-${{ hashFiles('.github/workflows/ci.yml', 'nx.json', '**/project.json', 'pnpm-lock.yaml', 'tsconfig*.json') }}
          restore-keys: |
            ${{ runner.os }}-nx-v3-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Check dependency versions (PRs)
        if: github.event_name == 'pull_request'
        run: pnpm nx syncpack:lint bibgraph

      - name: Fix dependency versions (main branch)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          pnpm syncpack fix-mismatches
          pnpm syncpack format

      - name: Check for changes
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        id: changes
        run: |
          if git diff --quiet; then
            echo "changed=false" >> "$GITHUB_OUTPUT"
          else
            echo "changed=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Update lockfile and commit fixes
        if: github.event_name == 'push' && github.ref == 'refs/heads/main' && steps.changes.outputs.changed == 'true'
        run: |
          pnpm install --no-frozen-lockfile
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "chore(deps): auto-fix syncpack mismatches [skip ci]"
          git push

  # Main validation job - build, typecheck, lint, and all tests in one job
  # Consolidating reduces setup overhead and lets Nx fully optimize the task graph
  validate:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    outputs:
      should-deploy: ${{ steps.deploy.outputs.should-deploy }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js with pnpm cache
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Setup Nx cache
        uses: actions/cache@v4
        with:
          # Cache full .nx dir (includes workspace-data DB) for cross-run cache sharing
          path: .nx
          key: ${{ runner.os }}-nx-v3-${{ hashFiles('.github/workflows/ci.yml', 'nx.json', '**/project.json', 'pnpm-lock.yaml', 'tsconfig*.json') }}
          restore-keys: |
            ${{ runner.os }}-nx-v3-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build and typecheck all projects
        timeout-minutes: 25
        env:
          GITHUB_PAGES: true
          NODE_OPTIONS: --max-old-space-size=8192
        run: pnpm nx run-many -t build typecheck --parallel=3

      - name: Lint all projects
        timeout-minutes: 20
        env:
          NODE_OPTIONS: --max-old-space-size=8192
        run: pnpm nx run-many -t lint --parallel=3

      - name: Run tests (except algorithms)
        timeout-minutes: 20
        env:
          NODE_OPTIONS: --max-old-space-size=8192
        run: pnpm nx run-many -t test:unit test:component test:integration --exclude=algorithms --parallel=2

      - name: Run algorithms tests separately
        timeout-minutes: 25
        env:
          NODE_OPTIONS: --max-old-space-size=6144
          NX_PARALLEL: 1
          CI: true
        run: |
          cd packages/algorithms
          npx vitest run --reporter=verbose --no-coverage  --test-timeout=45000

      - name: Upload build artifacts
        uses: actions/upload-artifact@v5
        with:
          name: build-artifacts
          path: |
            apps/web/dist
            apps/cli/dist
            packages/*/dist
          retention-days: 1

      - name: Upload coverage
        uses: actions/upload-artifact@v5
        if: always()
        with:
          name: coverage-all
          path: coverage/
          retention-days: 7
          if-no-files-found: ignore

      - name: Determine deployment
        id: deploy
        run: |
          if [ "${{ github.event_name }}" = "push" ] && [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "should-deploy=true" >> "${GITHUB_OUTPUT}"
          else
            echo "should-deploy=false" >> "${GITHUB_OUTPUT}"
          fi

  # Security audit - Check for vulnerabilities (runs in parallel with validate)
  security-audit:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js with pnpm cache
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run security audit
        run: pnpm audit --audit-level moderate

  # Setup E2E sharding matrix dynamically from E2E_SHARDS env var
  setup-e2e:
    runs-on: ubuntu-latest
    timeout-minutes: 2
    outputs:
      shards: ${{ steps.set-matrix.outputs.shards }}
    steps:
      - name: Generate shard matrix
        id: set-matrix
        run: |
          shards="[$(seq -s, 1 "$E2E_SHARDS")]"
          echo "shards=$shards" >> "$GITHUB_OUTPUT"
          echo "Generated shard matrix: $shards"

  # E2E tests - Full application tests (run after validate)
  # Uses matrix sharding to run tests in parallel across E2E_SHARDS runners
  e2e:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: [validate, setup-e2e]
    if: always() && needs.validate.result == 'success'
    strategy:
      fail-fast: true
      matrix:
        shard: ${{ fromJson(needs.setup-e2e.outputs.shards) }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Download build artifacts
        uses: actions/download-artifact@v6
        with:
          name: build-artifacts
          path: .

      - name: Validate build artifacts
        run: |
          if [ ! -d "apps/web/dist" ]; then
            echo "Error: Build artifacts missing - apps/web/dist not found"
            exit 1
          fi
          echo "Build artifacts validated successfully"

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('pnpm-lock.yaml') }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Install Playwright browsers
        run: pnpm exec playwright install --with-deps

      - name: Run E2E tests (shard ${{ matrix.shard }}/${{ env.E2E_SHARDS }})
        run: |
          cd apps/web

          # Run Playwright tests with JSON output to temporary file to avoid corruption
          # Use list reporter for console output, JSON reporter for clean results
          pnpm exec playwright test \
            --shard=${{ matrix.shard }}/${{ env.E2E_SHARDS }} \
            --reporter=list,json \
            2>test-results/console-output.log \
            || {
            TEST_EXIT_CODE=$?
            echo "Playwright tests completed with exit code: $TEST_EXIT_CODE"

            # Copy the JSON results to expected location if it exists
            if [ -f "test-results/results.json" ]; then
              echo "‚úÖ JSON results file created successfully"
              # Validate JSON integrity
              if jq empty "test-results/results.json" 2>/dev/null; then
                echo "‚úÖ JSON results file is valid"
              else
                echo "‚ö†Ô∏è JSON results file is corrupted, showing first 200 characters:"
                head -200 "test-results/results.json" | cat -v
              fi
            else
              echo "‚ö†Ô∏è No JSON results file found"
            fi

            # Analyze the actual test results to determine if this is a real failure
            echo "üîç Analyzing test results to distinguish between flaky passes and actual failures..."

            # Check for various possible result file locations
            RESULTS_FILE=""
            if [ -f "test-results/results.json" ]; then
              RESULTS_FILE="test-results/results.json"
            elif [ -f "blob-report/results.json" ]; then
              RESULTS_FILE="blob-report/results.json"
            else
              # Look for any JSON files that might contain results
              RESULTS_FILE=$(find test-results -name "*.json" -type f -exec file {} \; | grep "JSON" | cut -d: -f1 | head -1)
            fi

            if [ -n "$RESULTS_FILE" ] && [ -f "$RESULTS_FILE" ]; then
              echo "üìÑ Found results file: $RESULTS_FILE"

              # Try to parse the JSON results safely
              if jq empty "$RESULTS_FILE" 2>/dev/null; then
                echo "‚úÖ Results file is valid JSON, analyzing..."

                # Get test summary from the results
                TOTAL_SPECS=$(jq -r '[.projects[]?.suites[]?.specs[]?] | length' "$RESULTS_FILE" 2>/dev/null || echo "0")
                TOTAL_TESTS=$(jq -r '[.projects[]?.suites[]?.specs[]?.tests[]?] | length' "$RESULTS_FILE" 2>/dev/null || echo "0")

                echo "üìä Test Statistics:"
                echo "  Total test specs: $TOTAL_SPECS"
                echo "  Total individual tests: $TOTAL_TESTS"

                if [ "$TOTAL_TESTS" -gt 0 ]; then
                  # Count different test outcomes
                  PASSED_TESTS=$(jq -r '[.projects[]?.suites[]?.specs[]?.tests[]? | select(.results[-1].status == "passed")] | length' "$RESULTS_FILE" 2>/dev/null || echo "0")
                  FAILED_TESTS=$(jq -r '[.projects[]?.suites[]?.specs[]?.tests[]? | select(.results[-1].status == "unexpected")] | length' "$RESULTS_FILE" 2>/dev/null || echo "0")
                  SKIPPED_TESTS=$(jq -r '[.projects[]?.suites[]?.specs[]?.tests[]? | select(.results[-1].status == "skipped")] | length' "$RESULTS_FILE" 2>/dev/null || echo "0")
                  FLAKY_TESTS=$(jq -r '[.projects[]?.suites[]?.specs[]?.tests[]? | select(.results | length > 1)] | length' "$RESULTS_FILE" 2>/dev/null || echo "0")

                  echo "  Passed: $PASSED_TESTS"
                  echo "  Failed: $FAILED_TESTS"
                  echo "  Skipped: $SKIPPED_TESTS"
                  echo "  Flaky: $FLAKY_TESTS"

                                  # Alternative: Check if JSON structure is what we expect
                  # If not, fall back to console output analysis
                  if [ "$TOTAL_TESTS" -gt 0 ]; then
                    echo "‚úÖ Found test data in JSON, analyzing..."
                    # The key logic: if there are no failed tests, treat as success
                    if [ "$FAILED_TESTS" -eq 0 ]; then
                      echo "‚úÖ All tests passed (some may have been flaky but eventually succeeded)."
                      echo "üéâ Treating the test run as successful."
                      exit 0
                    else
                      echo "‚ùå Found $FAILED_TESTS failed test(s). This represents actual test failures."
                      echo "üîç Failed tests:"
                      jq -r '.projects[]?.suites[]?.specs[]?.tests[]? | select(.results[-1].status == "unexpected") | "  - \(.title // \"Unnamed test\")"' "$RESULTS_FILE" 2>/dev/null || echo "  (Could not extract test names)"
                      echo "üíæ Check the uploaded HTML report for detailed failure information."
                      exit 1
                    fi
                  else
                    echo "‚ö†Ô∏è JSON structure different than expected. Falling back to console output analysis..."
                    # Look for pass/fail counts in console output if captured
                    echo "üîç Playwright exit code: $TEST_EXIT_CODE"
                    echo "üìä Treating as failure due to parsing issues."
                    exit 1
                  fi
                else
                  echo "‚ö†Ô∏è No tests were found in the results. This might indicate:"
                  echo "  - Test discovery issues"
                  echo "  - Configuration problems"
                  echo "  - Empty test shard"
                  echo "üîç Playwright exit code: $TEST_EXIT_CODE"
                  exit 1
                fi
              else
                echo "‚ö†Ô∏è Results file exists but is not valid JSON."
                echo "üîç File content preview:"
                head -20 "$RESULTS_FILE" 2>/dev/null || echo "Could not read file"
                exit $TEST_EXIT_CODE
              fi
            else
              echo "‚ö†Ô∏è No test results file found. This indicates a test execution failure."
              echo "üîç Searching for test-related files..."
              find test-results -type f -name "*.json" -o -name "*.txt" -o -name "*.log" 2>/dev/null | head -10 | sed 's/^/  /' || echo "  (No files found)"
              echo "üîç Playwright exit code: $TEST_EXIT_CODE"
              echo "üíæ This likely indicates a test infrastructure problem rather than test failures."
              exit $TEST_EXIT_CODE
            fi
          }

      - name: Upload E2E artifacts
        uses: actions/upload-artifact@v5
        if: failure()
        with:
          name: playwright-report-shard-${{ matrix.shard }}
          path: apps/web/test-results/
          retention-days: 7

  # Aggregate coverage and generate reports
  coverage:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [validate]
    if: always() && needs.validate.result == 'success'
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Download coverage artifacts
        id: download-coverage
        uses: actions/download-artifact@v6
        continue-on-error: true
        with:
          name: coverage-all
          path: coverage/

      - name: Check coverage availability
        id: coverage-check
        run: |
          if [ -d "coverage" ] && [ "$(ls -A coverage 2>/dev/null)" ]; then
            echo "has-coverage=true" >> "${GITHUB_OUTPUT}"
            echo "Coverage artifacts found"
          else
            echo "has-coverage=false" >> "${GITHUB_OUTPUT}"
            echo "No coverage artifacts found - skipping coverage report"
          fi

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Generate workspace coverage report
        if: steps.coverage-check.outputs.has-coverage == 'true'
        run: pnpm coverage:report

      - name: Upload coverage to Codecov
        if: steps.coverage-check.outputs.has-coverage == 'true'
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage/workspace-coverage.json
          flags: unittests
          name: codecov-umbrella

      - name: Upload final coverage reports
        if: steps.coverage-check.outputs.has-coverage == 'true'
        uses: actions/upload-artifact@v5
        with:
          name: final-coverage-reports
          path: coverage/
          retention-days: 30

      - name: Coverage skipped summary
        if: steps.coverage-check.outputs.has-coverage != 'true'
        run: |
          {
            echo "## Coverage Report Skipped"
            echo "No coverage artifacts were uploaded from the validate job."
            echo "To generate coverage, run tests with the \`--coverage\` flag."
          } >> "${GITHUB_STEP_SUMMARY}"

  # Accessibility tests (pa11y via Nx)
  test-accessibility:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [validate]
    if: always() && needs.validate.result == 'success' && (github.ref == 'refs/heads/main' || contains(github.event.pull_request.labels.*.name, 'a11y-check'))
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Download build artifacts
        uses: actions/download-artifact@v6
        with:
          name: build-artifacts
          path: .

      - name: Install pa11y-ci
        run: npm install -g pa11y-ci

      - name: Run accessibility tests
        run: pnpm nx test:accessibility web
        continue-on-error: true

      - name: Upload accessibility report
        uses: actions/upload-artifact@v5
        if: always()
        with:
          name: accessibility-report
          path: pa11y-ci-report/
          retention-days: 7
          if-no-files-found: ignore

  # Performance tests (Lighthouse via Nx)
  test-performance:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [validate]
    if: always() && needs.validate.result == 'success' && (github.ref == 'refs/heads/main' || contains(github.event.pull_request.labels.*.name, 'perf-check'))
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Download build artifacts
        uses: actions/download-artifact@v6
        with:
          name: build-artifacts
          path: .

      - name: Install Lighthouse CI
        run: npm install -g @lhci/cli@0.13.x

      - name: Run performance tests
        run: pnpm nx test:performance web
        continue-on-error: true
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: Upload Lighthouse report
        uses: actions/upload-artifact@v5
        if: always()
        with:
          name: lighthouse-report
          path: .lighthouseci/
          retention-days: 7
          if-no-files-found: ignore

  # Deployment
  deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [validate, e2e, security-audit]
    if: always() && needs.validate.outputs.should-deploy == 'true' && github.ref == 'refs/heads/main' && needs.validate.result == 'success' && (needs.e2e.result == 'success' || needs.e2e.result == 'skipped') && needs.security-audit.result == 'success'
    environment:
      name: production
      url: https://mearman.github.io/BibGraph/
    permissions:
      contents: read
      pages: write
      id-token: write
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Install dependencies
        timeout-minutes: 5
        run: pnpm install --frozen-lockfile

      - name: Download build artifacts
        uses: actions/download-artifact@v6
        with:
          name: build-artifacts
          path: .

      - name: Install PostHog CLI
        run: npm install -g @posthog/cli

      - name: Inject source map metadata
        run: posthog-cli --host https://eu.posthog.com sourcemap inject --version ${{ github.sha }} --directory ./apps/web/dist
        env:
          POSTHOG_CLI_TOKEN: ${{ secrets.POSTHOG_CLI_TOKEN }}
          POSTHOG_CLI_ENV_ID: ${{ secrets.POSTHOG_CLI_ENV_ID }}

      - name: Upload source maps to PostHog
        run: posthog-cli --host https://eu.posthog.com sourcemap upload --directory ./apps/web/dist --delete-after
        env:
          POSTHOG_CLI_TOKEN: ${{ secrets.POSTHOG_CLI_TOKEN }}
          POSTHOG_CLI_ENV_ID: ${{ secrets.POSTHOG_CLI_ENV_ID }}

      - name: Upload build artifacts
        uses: actions/upload-pages-artifact@v4
        with:
          path: apps/web/dist

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Run smoke tests
        run: |
          sleep 30
          curl -f ${{ steps.deployment.outputs.page_url }} || exit 1

  # Post-deployment E2E tests against live GitHub Pages
  post-deploy-e2e:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: deploy
    if: false  # Disabled - full E2E suite takes 20-25 minutes and times out
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright browsers
        run: pnpm exec playwright install --with-deps

      - name: Wait for GitHub Pages propagation
        run: |
          echo "Waiting for GitHub Pages to be fully propagated..."
          sleep 60

      - name: Run comprehensive E2E tests against live site
        env:
          E2E_BASE_URL: "https://mearman.github.io/BibGraph/"
          E2E_FULL_SUITE: "true"
          CI: "true"
        run: |
          echo "Running E2E tests against live GitHub Pages site..."
          pnpm nx test:e2e web

      - name: Upload post-deployment E2E artifacts
        uses: actions/upload-artifact@v5
        if: failure()
        with:
          name: post-deploy-e2e-report
          path: test-results/playwright-report/
          retention-days: 7

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v8
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'üö® Post-Deployment E2E Test Failure',
              body: `Post-deployment E2E tests failed against the live GitHub Pages site.

              **Deployment URL**: https://mearman.github.io/BibGraph/
              **Workflow Run**: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}
              **Commit**: ${context.sha}

              Please investigate the deployment and rollback if necessary.

              Steps taken:
              - ‚úÖ Build and test completed
              - ‚úÖ Deployment to GitHub Pages completed
              - ‚ùå Post-deployment E2E tests failed

              The rollback job should trigger automatically to restore the previous working version.`,
              labels: ['bug', 'ci/cd', 'urgent']
            })

  # Release automation
  release:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [validate, e2e, security-audit, deploy]
    if: always() && needs.validate.result == 'success' && (needs.e2e.result == 'success' || needs.e2e.result == 'skipped') && needs.security-audit.result == 'success' && needs.deploy.result == 'success' && github.ref == 'refs/heads/main'
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: "22"

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Configure Git
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: Run semantic-release
        run: |
          npx semantic-release || {
            echo "Semantic-release failed or no changes to release"
            echo "This is normal if no conventional commits warrant a release"
            exit 0
          }
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Automatic rollback on post-deployment E2E failure
  rollback:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: post-deploy-e2e
    if: failure() && needs.post-deploy-e2e.result == 'failure' && github.ref == 'refs/heads/main'
    permissions:
      contents: write
      pages: write
      id-token: write
      issues: write
    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Get previous successful deployment
        id: previous-deployment
        run: |
          echo "Finding previous successful GitHub Pages deployment..."

          # Get the list of Pages deployments
          deployments=$(curl -s \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/${{ github.repository }}/pages/deployments)

          # Find the most recent successful deployment (excluding current failed one)
          previous_deployment_id=$(echo "$deployments" | jq '[.[] | select(.status == "succeeded" and .updated_at < "'"$(date -u +%Y-%m-%dT%H:%M:%SZ)"'")] | sort_by(.updated_at) | reverse | .[0].id')

          if [ "$previous_deployment_id" = "null" ] || [ -z "$previous_deployment_id" ]; then
            echo "No previous successful deployment found"
            echo "deployment_id=" >> "${GITHUB_OUTPUT}"
            exit 1
          fi

          echo "deployment_id=$previous_deployment_id" >> "${GITHUB_OUTPUT}"
          echo "Previous successful deployment ID: $previous_deployment_id"

      - name: Rollback to previous deployment
        if: steps.previous-deployment.outputs.deployment_id != ''
        run: |
          echo "Rolling back to deployment ID: ${{ steps.previous-deployment.outputs.deployment_id }}"

          # Cancel current deployment if still active
          current_deployments=$(curl -s \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/${{ github.repository }}/pages/deployments)

          current_id=$(echo "$current_deployments" | jq '.[0].id')

          if [ "$current_id" != "null" ] && [ -n "$current_id" ]; then
            curl -X POST \
              -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/${{ github.repository }}/pages/deployments/$current_id/cancel"
            echo "Cancelled current deployment: $current_id"
          fi

          # Promote previous successful deployment
          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/pages/deployments/${{ steps.previous-deployment.outputs.deployment_id }}/promote"

          echo "Rollback initiated successfully"

      - name: Create rollback issue
        if: steps.previous-deployment.outputs.deployment_id != ''
        uses: actions/github-script@v8
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'üîÑ Automatic Rollback Completed',
              body: `The GitHub Pages deployment has been automatically rolled back due to post-deployment E2E test failures.

              **Previous Deployment ID**: ${{ steps.previous-deployment.outputs.deployment_id }}
              **Live Site**: https://mearman.github.io/BibGraph/
              **Workflow Run**: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}
              **Failed Commit**: ${context.sha}

              **What happened:**
              - ‚úÖ Build and test completed successfully
              - ‚úÖ Deployment to GitHub Pages completed
              - ‚ùå Post-deployment E2E tests failed
              - üîÑ Automatic rollback to previous successful deployment completed

              **Next steps:**
              1. Investigate the E2E test failures in the workflow run
              2. Review the deployment artifacts and test reports
              3. Fix the issues and retry deployment
              4. Monitor the next deployment's post-deployment tests

              The site should now be restored to the previous working version.`,
              labels: ['ci/cd', 'rollback', 'resolved']
            })

      - name: Wait for rollback propagation
        if: steps.previous-deployment.outputs.deployment_id != ''
        run: |
          echo "Waiting for rollback to propagate..."
          sleep 30

          # Verify rollback is working
          max_attempts=10
          attempt=1

          while [ $attempt -le $max_attempts ]; do
            echo "Checking rollback status (attempt $attempt/$max_attempts)..."

            if curl -f -s "https://mearman.github.io/BibGraph/" > /dev/null; then
              echo "‚úÖ Rollback verified - site is accessible"
              break
            fi

            if [ $attempt -eq $max_attempts ]; then
              echo "‚ö†Ô∏è Rollback verification failed after $max_attempts attempts"
              exit 1
            fi

            sleep 30
            attempt=$((attempt + 1))
          done

  # Results and notifications
  results:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [validate, security-audit, e2e, coverage, test-accessibility, test-performance, deploy, post-deploy-e2e, release, rollback]
    if: always()
    steps:
      - name: Download coverage reports
        if: needs.coverage.result == 'success'
        uses: actions/download-artifact@v6
        continue-on-error: true
        with:
          name: final-coverage-reports
          path: coverage/

      - name: Generate results summary
        run: |
          {
            echo "# üìä CI/CD Pipeline Results"
            echo ""
            echo "| Job | Status | Details |"
            echo "|-----|--------|---------|"
            echo "| ‚úÖ Validate | ${{ needs.validate.result }} | Build + typecheck + lint + all tests |"
            echo "| üîí Security Audit | ${{ needs.security-audit.result }} | Vulnerability scanning |"
            echo "| üé≠ E2E Tests | ${{ needs.e2e.result }} | Full E2E suite |"
            echo "| üìà Coverage | ${{ needs.coverage.result }} | Workspace coverage report |"
            echo "| ‚ôø Accessibility | ${{ needs.test-accessibility.result }} | pa11y WCAG 2.1 AA |"
            echo "| ‚ö° Performance | ${{ needs.test-performance.result }} | Lighthouse CI |"
            echo "| üöÄ Deploy | ${{ needs.deploy.result }} | ${{ needs.validate.outputs.should-deploy == 'true' && 'GitHub Pages (after all tests pass)' || 'Skipped' }} |"
            echo "| üéØ Post-Deploy E2E | ${{ needs.post-deploy-e2e.result }} | ${{ needs.post-deploy-e2e.result == 'success' && 'Live site verification passed' || (needs.post-deploy-e2e.result == 'skipped' && 'Not run' || 'Live site verification failed') }} |"
            echo "| üîÑ Rollback | ${{ needs.rollback.result }} | ${{ needs.rollback.result == 'success' && 'Automatic rollback completed' || (needs.rollback.result == 'skipped' && 'Not needed' || 'Rollback failed') }} |"
            echo "| üì¶ Release | ${{ needs.release.result }} | ${{ needs.release.result == 'success' && 'Release created successfully' || (needs.release.result == 'skipped' && 'Not created (failed post-deploy E2E)' || 'Release failed') }} |"
          } >> "${GITHUB_STEP_SUMMARY}"

      - name: Coverage summary
        if: needs.coverage.result == 'success'
        run: |
          if [ -f coverage/workspace-coverage.json ]; then
            OVERALL=$(jq -r '.overall' coverage/workspace-coverage.json)
            LINES=$(jq -r '.totals.lines.percentage' coverage/workspace-coverage.json)
            FUNCTIONS=$(jq -r '.totals.functions.percentage' coverage/workspace-coverage.json)

            {
              echo "## üìà Coverage Summary"
              echo ""
              echo "- **Overall Coverage**: ${OVERALL}%"
              echo "- **Lines Coverage**: ${LINES}%"
              echo "- **Functions Coverage**: ${FUNCTIONS}%"
            } >> "${GITHUB_STEP_SUMMARY}"
          fi

      - name: Notification on failure
        if: failure()
        run: |
          echo "‚ùå Pipeline failed! Check the individual job logs for details." >> "${GITHUB_STEP_SUMMARY}"
          exit 1

      - name: Success notification
        if: success()
        run: |
          echo "üéâ All checks passed! Ready for merge/deployment." >> "${GITHUB_STEP_SUMMARY}"