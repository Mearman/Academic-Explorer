/**
 * Disk Cache Tests - Development Mode Disk Writing Functionality
 *
 * Tests for static data caching system that writes to disk during development
 * for faster subsequent loads and data persistence across sessions.
 */

import {
  describe,
  it,
  expect,
  beforeEach,
  afterEach,
  vi,
  type MockedFunction,
} from "vitest";
import { vol } from "memfs";
import {
  DiskCacheWriter,
  type DiskWriterConfig,
  type InterceptedData,
} from "../disk/disk-writer";

// Mock the file system
vi.mock("fs", () => import("memfs").then((fs) => ({ ...fs.fs })));
vi.mock("fs/promises", () =>
  import("memfs").then((fs) => ({ ...fs.fs.promises })),
);
vi.mock("path", () => import("path"));
vi.mock("crypto", () => import("crypto"));

// Mock Node.js modules
vi.mock("node:fs", () =>
  import("memfs").then((fs) => ({ promises: fs.fs.promises })),
);
vi.mock("node:path", () => import("path"));
vi.mock("node:crypto", () => import("crypto"));

// Mock logger
vi.mock("@academic-explorer/utils/logger", () => ({
  logger: { debug: vi.fn(), info: vi.fn(), warn: vi.fn(), error: vi.fn() },
  logError: vi.fn(),
}));

// Mock cache utilities
vi.mock("@academic-explorer/utils/static-data/cache-utilities", () => ({
  generateContentHash: vi.fn(() => "mock-hash"),
  getCacheFilePath: vi.fn(
    (url: string) => `/mock/cache/${url.replace(/[^a-zA-Z0-9]/g, "_")}.json`,
  ),
  hasCollision: vi.fn(() => false),
  mergeCollision: vi.fn(),
  migrateToMultiUrl: vi.fn((entry) => entry),
  validateFileEntry: vi.fn(() => true),
}));

describe.skip("DiskCache - Development Mode", () => {
  let diskCache: DiskCacheWriter;

  beforeEach(async () => {
    // Reset the in-memory file system
    vol.reset();

    diskCache = new DiskCacheWriter({
      basePath: "/tmp/test-cache",
      maxConcurrentWrites: 1,
      lockTimeoutMs: 5000,
      checkDiskSpace: false,
      minDiskSpaceBytes: 1024 * 1024, // 1MB for testing
    });
  });

  afterEach(() => {
    vi.clearAllMocks();
    vol.reset();
  });

  describe("Basic Operations", () => {
    it("should write data to disk successfully", async () => {
      const testData = { id: "W123", title: "Test Work", year: 2023 };
      const interceptedData: InterceptedData = {
        url: "https://api.openalex.org/works/W123",
        method: "GET",
        requestHeaders: { Accept: "application/json" },
        responseData: testData,
        statusCode: 200,
        responseHeaders: { "content-type": "application/json" },
        timestamp: new Date().toISOString(),
      };

      await diskCache.writeToCache(interceptedData);

      const fs = await import("fs/promises");
      const exists = await fs
        .access("/tmp/test-cache")
        .then(() => true)
        .catch(() => false);
      expect(exists).toBe(true);
    });

    it("should handle multiple writes", async () => {
      const testData1 = { id: "W123", title: "Test Work 1" };
      const testData2 = { id: "A456", name: "Test Author" };

      const interceptedData1: InterceptedData = {
        url: "https://api.openalex.org/works/W123",
        method: "GET",
        requestHeaders: { Accept: "application/json" },
        responseData: testData1,
        statusCode: 200,
        responseHeaders: { "content-type": "application/json" },
        timestamp: new Date().toISOString(),
      };

      const interceptedData2: InterceptedData = {
        url: "https://api.openalex.org/authors/A456",
        method: "GET",
        requestHeaders: { Accept: "application/json" },
        responseData: testData2,
        statusCode: 200,
        responseHeaders: { "content-type": "application/json" },
        timestamp: new Date().toISOString(),
      };

      await diskCache.writeToCache(interceptedData1);
      await diskCache.writeToCache(interceptedData2);

      const fs = await import("fs/promises");
      const files = await fs.readdir("/tmp/test-cache").catch(() => []);
      expect(files.length).toBeGreaterThan(0);
    });
  });

  describe("Directory Management", () => {
    it("should create directory structure automatically", async () => {
      const fs = await import("fs/promises");

      const interceptedData: InterceptedData = {
        url: "https://api.openalex.org/works/W123",
        method: "GET",
        requestHeaders: { Accept: "application/json" },
        responseData: { test: true },
        statusCode: 200,
        responseHeaders: { "content-type": "application/json" },
        timestamp: new Date().toISOString(),
      };

      await diskCache.writeToCache(interceptedData);

      const exists = await fs
        .access("/tmp/test-cache")
        .then(() => true)
        .catch(() => false);
      expect(exists).toBe(true);
    });
  });

  describe("Configuration", () => {
    it("should accept custom configuration", async () => {
      const customCache = new DiskCacheWriter({
        basePath: "/tmp/custom-cache",
        maxConcurrentWrites: 5,
        lockTimeoutMs: 10000,
        checkDiskSpace: true,
        minDiskSpaceBytes: 10 * 1024 * 1024, // 10MB
      });

      const interceptedData: InterceptedData = {
        url: "https://api.openalex.org/works/W123",
        method: "GET",
        requestHeaders: { Accept: "application/json" },
        responseData: { id: "W123" },
        statusCode: 200,
        responseHeaders: { "content-type": "application/json" },
        timestamp: new Date().toISOString(),
      };

      await customCache.writeToCache(interceptedData);

      const fs = await import("fs/promises");
      const exists = await fs
        .access("/tmp/custom-cache")
        .then(() => true)
        .catch(() => false);
      expect(exists).toBe(true);
    });
  });

  describe("Error Handling", () => {
    it("should handle invalid URLs gracefully", async () => {
      const invalidData: InterceptedData = {
        url: "not-a-valid-url",
        method: "GET",
        requestHeaders: {},
        responseData: { error: true },
        statusCode: 200,
        responseHeaders: { "content-type": "application/json" },
        timestamp: new Date().toISOString(),
      };

      // Should not throw
      await expect(diskCache.writeToCache(invalidData)).resolves.not.toThrow();
    });

    it("should handle missing response data", async () => {
      const emptyData: InterceptedData = {
        url: "https://api.openalex.org/works/W123",
        method: "GET",
        requestHeaders: { Accept: "application/json" },
        responseData: null as any,
        statusCode: 200,
        responseHeaders: { "content-type": "application/json" },
        timestamp: new Date().toISOString(),
      };

      await expect(diskCache.writeToCache(emptyData)).resolves.not.toThrow();
    });

    it.skip("should handle TTL expiration", async () => {
      // TODO: Implement TTL functionality in DiskCacheWriter or create appropriate test
      expect(true).toBe(true);
    });

    it("should automatically delete expired entries on read", async () => {
      const shortTtlCache = new DiskCacheWriter({
        basePath: "/tmp/test-cache",
        ttl: 50,
      });

      await shortTtlCache.write("expires:fast", { data: "will be deleted" });

      // Wait for expiration
      await new Promise((resolve) => setTimeout(resolve, 100));

      await shortTtlCache.read("expires:fast");

      // File should be deleted
      const fs = await import("fs/promises");
      const exists = await fs
        .access("/tmp/test-cache/expires:fast.json")
        .then(() => true)
        .catch(() => false);
      expect(exists).toBe(false);
    });
  });

  describe("Error Handling", () => {
    it("should handle write errors gracefully", async () => {
      const disabledCache = new DiskCacheWriter({ enabled: false });

      await expect(
        disabledCache.write("test:key", { data: "test" }),
      ).rejects.toThrow("Disk cache is disabled");
    });

    it("should handle read errors for corrupted files", async () => {
      const fs = await import("fs/promises");

      // Create a corrupted file
      await fs.mkdir("/tmp/test-cache", { recursive: true });
      await fs.writeFile(
        "/tmp/test-cache/corrupted:file.json",
        "invalid json {",
      );

      const result = await diskCache.read("corrupted:file");
      expect(result).toBeNull();
    });

    it("should handle permission errors gracefully", async () => {
      const fs = await import("fs/promises");
      const originalWriteFile = fs.writeFile as MockedFunction<
        typeof fs.writeFile
      >;

      originalWriteFile.mockRejectedValueOnce(
        new Error("EACCES: permission denied"),
      );

      await expect(
        diskCache.write("permission:denied", { data: "test" }),
      ).rejects.toThrow("EACCES: permission denied");
    });

    it("should handle disk space errors", async () => {
      const fs = await import("fs/promises");
      const originalWriteFile = fs.writeFile as MockedFunction<
        typeof fs.writeFile
      >;

      originalWriteFile.mockRejectedValueOnce(
        new Error("ENOSPC: no space left on device"),
      );

      await expect(
        diskCache.write("no:space", { data: "test" }),
      ).rejects.toThrow("ENOSPC: no space left on device");
    });
  });

  describe("Cache Statistics", () => {
    it("should return accurate cache statistics", async () => {
      await diskCache.write("stats:test1", { size: "small" });
      await diskCache.write("stats:test2", { size: "medium" });
      await diskCache.write("stats:test3", { size: "large" });

      const stats = await diskCache.getStats();

      expect(stats.totalFiles).toBe(3);
      expect(stats.totalSize).toBeGreaterThan(0);
      expect(stats.oldestEntry).toBeTypeOf("number");
    });

    it("should handle empty cache statistics", async () => {
      const stats = await diskCache.getStats();

      expect(stats.totalFiles).toBe(0);
      expect(stats.totalSize).toBe(0);
      expect(stats.oldestEntry).toBeNull();
    });
  });

  describe("Large Data Handling", () => {
    it("should handle large objects efficiently", async () => {
      const largeData = {
        id: "W999999",
        abstract: "A".repeat(10000), // 10KB abstract
        citations: Array.from({ length: 1000 }, (_, i) => ({
          id: `W${i}`,
          title: `Work ${i}`,
        })),
        metadata: {
          processed: true,
          version: "2.0",
          tags: Array.from({ length: 100 }, (_, i) => `tag-${i}`),
        },
      };

      const startTime = Date.now();
      await diskCache.write("large:dataset", largeData);
      const writeTime = Date.now() - startTime;

      const readStartTime = Date.now();
      const retrieved = await diskCache.read("large:dataset");
      const readTime = Date.now() - readStartTime;

      expect(retrieved).toEqual(largeData);
      expect(writeTime).toBeLessThan(1000); // Should complete within 1 second
      expect(readTime).toBeLessThan(500); // Should read within 500ms
    });

    it("should handle concurrent write operations", async () => {
      const promises = Array.from({ length: 10 }, (_, i) =>
        diskCache.write(`concurrent:${i}`, { id: i, data: `test-${i}` }),
      );

      await expect(Promise.all(promises)).resolves.not.toThrow();

      // Verify all writes succeeded
      const size = await diskCache.size();
      expect(size).toBe(10);
    });
  });

  describe("Edge Cases", () => {
    it("should handle special characters in cache keys", async () => {
      const specialKey = "special:chars!@#$%^&*()_+-=[]{}|;:,.<>?";
      const data = { message: "special characters work" };

      await diskCache.write(specialKey, data);
      const result = await diskCache.read(specialKey);

      expect(result).toEqual(data);
    });

    it("should handle empty and null data", async () => {
      await diskCache.write("empty:object", {});
      await diskCache.write("empty:array", []);
      await diskCache.write("null:value", null);
      await diskCache.write("undefined:value", undefined);

      expect(await diskCache.read("empty:object")).toEqual({});
      expect(await diskCache.read("empty:array")).toEqual([]);
      expect(await diskCache.read("null:value")).toBeNull();
      expect(await diskCache.read("undefined:value")).toBeUndefined();
    });

    it("should handle very long cache keys", async () => {
      const longKey = "very".repeat(100) + ":long:key";
      const data = { message: "long key works" };

      await diskCache.write(longKey, data);
      const result = await diskCache.read(longKey);

      expect(result).toEqual(data);
    });
  });

  describe("Development Mode Specific Features", () => {
    it("should support hot reload by detecting file changes", async () => {
      const fs = await import("fs/promises");

      await diskCache.write("hot:reload", { version: 1 });

      // Simulate external file modification
      const filePath = "/tmp/test-cache/hot:reload.json";
      const content = await fs.readFile(filePath, "utf-8");
      const entry: CacheEntry = JSON.parse(content);
      entry.data = { version: 2 };
      await fs.writeFile(filePath, JSON.stringify(entry, null, 2));

      const result = await diskCache.read("hot:reload");
      expect(result).toEqual({ version: 2 });
    });

    it("should maintain metadata for debugging", async () => {
      await diskCache.write("debug:metadata", { debug: true });

      const fs = await import("fs/promises");
      const content = await fs.readFile(
        "/tmp/test-cache/debug:metadata.json",
        "utf-8",
      );
      const entry: CacheEntry = JSON.parse(content);

      expect(entry.metadata).toMatchObject({
        entityType: "debug",
        entityId: "metadata",
        source: "api",
      });
      expect(entry.version).toBe("1.0");
      expect(entry.timestamp).toBeTypeOf("number");
    });

    it("should support cache warming during development", async () => {
      const warmupData = [
        { key: "warm:work1", data: { id: "W1", preloaded: true } },
        { key: "warm:work2", data: { id: "W2", preloaded: true } },
        { key: "warm:author1", data: { id: "A1", preloaded: true } },
      ];

      // Simulate cache warming
      const promises = warmupData.map((item) =>
        diskCache.write(item.key, item.data),
      );
      await Promise.all(promises);

      // Verify all entries are accessible
      const results = await Promise.all(
        warmupData.map((item) => diskCache.read(item.key)),
      );

      expect(results).toEqual(warmupData.map((item) => item.data));
    });
  });
});
